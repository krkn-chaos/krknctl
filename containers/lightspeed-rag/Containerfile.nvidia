# Generated by Claude Code
# krknctl Lightspeed RAG Container - NVIDIA GPU optimized with FAISS + llama.cpp
FROM registry.fedoraproject.org/fedora-minimal:42 AS builder

# Install build dependencies including CUDA toolkit
RUN microdnf -y install \
    python3 \
    python3-pip \
    python3-devel \
    curl \
    bash \
    git \
    gcc \
    gcc-c++ \
    cmake \
    make \
    && microdnf clean all

# Add NVIDIA repository for CUDA toolkit (if available)
RUN dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/fedora39/x86_64/cuda-fedora39.repo 2>/dev/null || true

# Set working directory
WORKDIR /app

# Create and activate virtual environment
RUN python3 -m venv /app/venv
ENV PATH="/app/venv/bin:$PATH"

# Install build dependencies first
RUN /app/venv/bin/pip install --no-cache-dir setuptools wheel scikit-build-core

# Clone krkn-lightspeed repository to get requirements_krknctl.txt
RUN git clone https://github.com/krkn-chaos/krkn-lightspeed.git /tmp/krkn-lightspeed && \
    cd /tmp/krkn-lightspeed && \
    git checkout krknctl_lightspeed_light && \
    echo "krkn-lightspeed repository cloned successfully"

# Clone krkn-hub repository to get scenario definitions
RUN git clone https://github.com/krkn-chaos/krkn-hub.git /tmp/krkn-hub && \
    echo "krkn-hub repository cloned successfully"

# Install dependencies from requirements_krknctl.txt
RUN /app/venv/bin/pip install --no-cache-dir -r /tmp/krkn-lightspeed/requirements_krknctl.txt

# Install llama-cpp-python with CUDA support
RUN CMAKE_ARGS="-DLLAMA_CUDA=on" /app/venv/bin/pip install --no-cache-dir --upgrade llama-cpp-python || \
    /app/venv/bin/pip install --no-cache-dir llama-cpp-python

# Download Llama 3.2 3B model
RUN mkdir -p /app/models && \
    /app/venv/bin/python -c "import huggingface_hub; huggingface_hub.hf_hub_download(repo_id='bartowski/Llama-3.2-3B-Instruct-GGUF', filename='Llama-3.2-3B-Instruct-Q4_K_M.gguf', local_dir='/app/models', local_dir_use_symlinks=False)" && \
    ls -la /app/models/ && \
    [ $(stat -c%s /app/models/Llama-3.2-3B-Instruct-Q4_K_M.gguf) -gt 1500000000 ] || (echo "Model download failed - file too small" && exit 1)

# Download sentence transformer model (all-MiniLM-L6-v2)
RUN mkdir -p /root/.cache/huggingface/transformers && \
    /app/venv/bin/python -c "from sentence_transformers import SentenceTransformer; model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"

# Copy application files from repository
RUN cp /tmp/krkn-lightspeed/rag_pipelines/llama31_krknctl_rag_pipeline.py /app/ && \
    cp /tmp/krkn-lightspeed/fastapi_app.py /app/ && \
    cp -r /tmp/krkn-lightspeed/utils /app/ && \
    rm -rf /tmp/krkn-lightspeed /tmp/krkn-hub

# Copy krknctl help
COPY krknctl_help.txt .

# Cleanup virtual environment
RUN find /app/venv -name "*.pyc" -delete && \
    find /app/venv -name "__pycache__" -type d -exec rm -rf {} + && \
    find /app/venv -name "*.pyo" -delete && \
    find /app/venv -name "*.egg-info" -type d -exec rm -rf {} + && \
    find /app/venv -name "tests" -type d -exec rm -rf {} + && \
    find /app/venv -name "test" -type d -exec rm -rf {} + && \
    rm -rf /tmp/* /root/.cache/pip

#############################################
# Runtime stage
#############################################
FROM registry.fedoraproject.org/fedora-minimal:42 AS runtime

# Install only essential runtime packages
RUN microdnf -y install python3 bash curl git && \
    microdnf clean all && \
    rm -rf /var/cache/dnf

WORKDIR /app

# Copy virtual environment and models
COPY --from=builder /app/venv/ /app/venv/
COPY --from=builder /app/models/ /app/models/
COPY --from=builder /app/krknctl_help.txt /app/krknctl_help.txt
COPY --from=builder /root/.cache/huggingface/ /root/.cache/huggingface/

# Copy application files
COPY --from=builder /app/llama31_krknctl_rag_pipeline.py /app/rag_pipelines/
COPY --from=builder /app/fastapi_app.py /app/
COPY --from=builder /app/utils/ /app/utils/

# Set environment for NVIDIA GPU
ENV PATH="/app/venv/bin:$PATH" \
    VIRTUAL_ENV="/app/venv" \
    CUDA_VISIBLE_DEVICES=0 \
    TORCH_USE_CUDA_DSA=1 \
    PYTHONUNBUFFERED=1

# Copy our implementation files
COPY rag_service.py .
COPY index_docs.py .

# Create directories for indices
RUN mkdir -p /app/docs_index /app/cached_docs /app/rag_pipelines

# Copy startup script
COPY entrypoint.sh .
RUN chmod +x entrypoint.sh

# Expose port for FastAPI service
EXPOSE 8080

# Set environment variables
ENV PYTHONUNBUFFERED=1

# CACHE INVALIDATION POINT: Change this ARG to force fresh code checkout
ARG CODE_VERSION=latest
RUN echo "Building with code version: $CODE_VERSION"

# Fresh clone of krkn-lightspeed repository (this layer will be invalidated when CODE_VERSION changes)
RUN rm -rf /app/rag_pipelines /app/fastapi_app.py /app/utils && \
    mkdir -p /app/rag_pipelines && \
    git clone https://github.com/krkn-chaos/krkn-lightspeed.git /tmp/krkn-lightspeed-fresh && \
    cd /tmp/krkn-lightspeed-fresh && \
    git checkout krknctl_lightspeed_light && \
    cp /tmp/krkn-lightspeed-fresh/rag_pipelines/llama31_krknctl_rag_pipeline.py /app/rag_pipelines/ && \
    cp /tmp/krkn-lightspeed-fresh/fastapi_app.py /app/ && \
    cp -r /tmp/krkn-lightspeed-fresh/utils /app/ && \
    rm -rf /tmp/krkn-lightspeed-fresh && \
    echo "Fresh krkn-lightspeed code updated successfully at version: $CODE_VERSION"

# Fresh clone of krkn-hub repository for scenario definitions
RUN git clone https://github.com/krkn-chaos/krkn-hub.git /tmp/krkn-hub-fresh && \
    echo "Fresh krkn-hub scenarios available for indexing at version: $CODE_VERSION" && \
    rm -rf /tmp/krkn-hub-fresh

# Run the entrypoint script
ENTRYPOINT ["./entrypoint.sh"]