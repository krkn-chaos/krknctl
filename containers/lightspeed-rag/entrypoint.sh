#!/bin/bash
# Generated by Claude Code
# Entrypoint script for krknctl Lightspeed RAG container

set -e

echo "Starting krknctl Lightspeed RAG service..."

# Create /dev/dri structure if GPU devices are mapped to different paths
if [ -c "/dev/card0" ] && [ -c "/dev/renderD128" ]; then
    echo "Creating /dev/dri structure for GPU access..."
    mkdir -p /dev/dri
    ln -sf /dev/card0 /dev/dri/card0
    ln -sf /dev/renderD128 /dev/dri/renderD128
    ls -la /dev/dri/
fi

# Check if we should use offline mode (env var set by krknctl)
USE_OFFLINE=${USE_OFFLINE:-"false"}

# Verify the model is available (should be pre-downloaded)
echo "Verifying Llama 3.2:1B model..."
MODEL_PATH="/app/models/llama-3.2-1b-instruct-q4_0.gguf"
if [ ! -f "$MODEL_PATH" ]; then
    echo "WARNING: Model not found at $MODEL_PATH"
    echo "Service will attempt to download it on first use"
else
    echo "Model verified: $(basename $MODEL_PATH)"
fi

# Handle documentation indexing based on online/offline mode
if [ "$USE_OFFLINE" = "true" ]; then
    echo "Using cached documentation (offline mode)"
    # Copy cached index to active location
    cp -r /app/cached_docs/* /app/docs_index/
else
    echo "Indexing live krknctl and krkn documentation..."
    python3 index_docs.py --live-index || {
        echo "Live indexing failed, falling back to cached documentation..."
        cp -r /app/cached_docs/* /app/docs_index/
    }
fi

# Start the RAG FastAPI service
echo "Starting RAG service on port 8080..."
exec python3 rag_service.py --host 0.0.0.0 --port 8080